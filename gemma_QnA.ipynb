{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    load_dotenv()\n",
    "\n",
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"google/gemma-7b-it\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    top_k=1,\n",
    "    top_p=0.9,    \n",
    "    temperature=0.1,\n",
    "    max_new_tokens = 500,\n",
    "    huggingfacehub_api_token=os.getenv('API_KEY')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check input given to model.\n",
    "def gemma_template(prompt):\n",
    "    text =  \"<start_of_turn>user\\n{}<end_of_turn>\".format(prompt) + \"\\n<start_of_turn>model\"    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hi! ðŸ‘‹\n",
      "\n",
      "It's nice to hear from you. What would you like to talk about today?\n"
     ]
    }
   ],
   "source": [
    "print(llm(gemma_template(\"hi\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm,\n",
    "                                 memory=memory,\n",
    "                                 verbose=True,\n",
    "                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I have changed the default Langchain template, So do the changes accordingly in your installed langchain files.\n",
    "#### The changes were made since gemma has its own chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      "{history}.\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:{input}\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.prompt import PROMPT\n",
    "print(PROMPT.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      ".\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:Hi\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello, human. I am here to interact with you. Please tell me what you would like me to do.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"Hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      "Human: Hi\n",
      "AI: Hello, human. I am here to interact with you. Please tell me what you would like me to do..\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:HOw are you\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I am doing well, thank you. How are you? I am ready to hear what you have to say.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"HOw are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      "Human: Hi\n",
      "AI: Hello, human. I am here to interact with you. Please tell me what you would like me to do.\n",
      "Human: HOw are you\n",
      "AI: I am doing well, thank you. How are you? I am ready to hear what you have to say..\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:My name is mayur\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello, Mayur. It's a pleasure to meet you. Please tell me what you would like me to do.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"My name is mayur\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      "Human: Hi\n",
      "AI: Hello, human. I am here to interact with you. Please tell me what you would like me to do.\n",
      "Human: HOw are you\n",
      "AI: I am doing well, thank you. How are you? I am ready to hear what you have to say.\n",
      "Human: My name is mayur\n",
      "AI: Hello, Mayur. It's a pleasure to meet you. Please tell me what you would like me to do..\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:What is the capital of India\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of India is Delhi.\n",
      "\n",
      "I have stored information about India's capital in my database and retrieved it when you asked.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"What is the capital of India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "<start_of_turn>user\n",
      "You are an AI that interacts with the Human. \n",
      "Just say what you are asked, No need to continue the conversation,behave like you are talking to a human\n",
      "\n",
      "Past conversations:\n",
      "Human: Hi\n",
      "AI: Hello, human. I am here to interact with you. Please tell me what you would like me to do.\n",
      "Human: HOw are you\n",
      "AI: I am doing well, thank you. How are you? I am ready to hear what you have to say.\n",
      "Human: My name is mayur\n",
      "AI: Hello, Mayur. It's a pleasure to meet you. Please tell me what you would like me to do.\n",
      "Human: What is the capital of India\n",
      "AI: The capital of India is Delhi.\n",
      "\n",
      "I have stored information about India's capital in my database and retrieved it when you asked..\n",
      "\n",
      "Below is the input given by the human,\n",
      "Human:What is my name?\n",
      "<end_of_turn>\n",
      "\n",
      "<start_of_turn>model\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Your name is Mayur, as you have previously told me. I have stored that information and retrieved it when you asked.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"What is my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
