{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    load_dotenv()\n",
    "\n",
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/google/gemma-7b-it\"\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(os.getenv('API_KEY'))}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)    \n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check input given to model.\n",
    "def prompt_template(prompt):\n",
    "    text =  \"<start_of_turn>user\\n{}<end_of_turn>\".format(prompt) + \"\\n<start_of_turn>model\"    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(prompt):\n",
    "    text =  prompt_template(prompt)   \n",
    "    \n",
    "    return query({\n",
    "        \"inputs\":text,\n",
    "        \"parameters\":{\"top_k\":2,\n",
    "                     \"top_p\":0.9,\n",
    "                     \"temperature\":0.5,\n",
    "                     \"max_length\":500}  \n",
    "        \n",
    "    })[0]['generated_text'][len(text):].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \n",
    "flew off and splattered me kitchen walls \n",
    "with smoothie! And to make matters worse,\n",
    "the warranty don't cover the cost of \n",
    "cleaning up me kitchen. I need yer help \n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English \n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "customer_email = customer_email.strip()\n",
    "style = style.strip()\n",
    "prompt = prompt.strip()\n",
    "# print(\"email:\\n\",customer_email,end=\"\\n\\n\")\n",
    "# print(\"style:\\n\",style,end='\\n\\n')\n",
    "# print(\"prompt:\\n\",prompt,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English \n",
      "in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid \n",
      "flew off and splattered me kitchen walls \n",
      "with smoothie! And to make matters worse,\n",
      "the warranty don't cover the cost of \n",
      "cleaning up me kitchen. I need yer help \n",
      "right now, matey!\n",
      "```<end_of_turn>\n",
      "<start_of_turn>model\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is the text translated into American English in a calm and respectful tone:\n",
      "\n",
      "\"I'm a bit frustrated that my blender lid flew off and splattered smoothie all over my kitchen walls. To top it all off, the warranty doesn't cover the cost of cleaning up the mess. I could really use your help right now, my friend.\"\n"
     ]
    }
   ],
   "source": [
    "print(output(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
