{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    load_dotenv()\n",
    "\n",
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Mayur\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"google/gemma-7b-it\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    top_k=1,\n",
    "    top_p=0.9,    \n",
    "    temperature=0.1,\n",
    "    max_new_tokens = 500,\n",
    "    huggingfacehub_api_token=os.getenv('API_KEY')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check input given to model.\n",
    "def gemma_template(prompt):\n",
    "    text =  \"<start_of_turn>user\\n{}<end_of_turn>\".format(prompt) + \"\\n<start_of_turn>model\"    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dose not work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True    \n",
    ")\n",
    "print(conversation.predict(input=gemma_template((\"HI\"))))\n",
    "conversation.predict(input=\"What is capital of india\")\n",
    "conversation.predict(input=\"What is my name\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"What is the capital of India\"\n",
    "first_prompt = ChatPromptTemplate.from_template(gemma_template(\"What is the best name to describe a company that makes {product}?,just give me one name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='<start_of_turn>user\\nWhat is the best name to describe a company that makes {product}?,just give me one name<end_of_turn>\\n<start_of_turn>model'))]), llm=HuggingFaceEndpoint(repo_id='google/gemma-7b-it', huggingfacehub_api_token='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', max_new_tokens=500, top_k=1, top_p=0.9, temperature=0.1, model='google/gemma-7b-it', client=<InferenceClient(model='google/gemma-7b-it', timeout=120)>, async_client=<InferenceClient(model='google/gemma-7b-it', timeout=120)>), output_key='ff')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_one = LLMChain(llm=llm,prompt=first_prompt)\n",
    "chain_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is one name for a company that makes queen size sheet sets:\n",
      "\n",
      "**Serene Sleep Company**\n"
     ]
    }
   ],
   "source": [
    "print(chain_one.run(\"Queen Size Sheet Set\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is one name for a company that makes steel:\\n\\n**Steel Forge**'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"What is the capital of India\"\n",
    "first_prompt = ChatPromptTemplate.from_template(gemma_template(\"What is the best name to describe a company that makes {product}?,just give me one name\"))\n",
    "second_prompt = ChatPromptTemplate.from_template(gemma_template(\"Write a 20 words description for the following  company:{company_name}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure, here is one name for a company that makes queen size sheet sets:\n",
      "\n",
      "**Serene Sleep Company**\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mSure, here is a 20 word description for the Serene Sleep Company:\n",
      "\n",
      "Serene Sleep Company specializes in crafting high-quality queen-size sheet sets using soft, breathable fabrics and luxurious designs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, here is a 20 word description for the Serene Sleep Company:\n",
      "\n",
      "Serene Sleep Company specializes in crafting high-quality queen-size sheet sets using soft, breathable fabrics and luxurious designs.\n"
     ]
    }
   ],
   "source": [
    "print(overall_simple_chain.run(\"Queen Size Sheet Set\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
